{import requests
from bs4 import BeautifulSoup
import csv


def scrape_acko_drive(url):
    
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    
    with open('acko_drive_cars.csv', 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['Car Name', 'Fuel Type', 'Transmission', 'Number of Available Colors', 'Price', 'Location of On-Road Price'])
        
        car_elements = soup.find_all('div', class_='product-tile')
        
        for car in car_elements:
            # Extract car details
            car_name = car.find('h3', class_='product-tile__title').text.strip()
            fuel_type = car.find('span', class_='fuel-type').text.strip()
            transmission = car.find('span', class_='transmission').text.strip()
            available_colors = len(car.find_all('div', class_='color-box'))
            price = car.find('span', class_='price').text.strip()
            on_road_price_location = car.find('span', class_='on-road-price__location').text.strip()
            
            writer.writerow([car_name, fuel_type, transmission, available_colors, price, on_road_price_location])
            
    print("Scraping completed!")

# URL of the Acko Drive website
url = "https://ackodrive.com/cars/?sortBy=price-high-low"
# Call the function to scrape the website
scrape_acko_drive(url)
